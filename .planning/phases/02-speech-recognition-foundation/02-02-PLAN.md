---
phase: 02-speech-recognition-foundation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - voice/AudioVisualizer.js
  - index.html
  - styles.css
autonomous: true

must_haves:
  truths:
    - "User can see a voice toggle button in teleprompter view"
    - "User can see animated waveform bars when audio is active"
    - "Waveform indicator appears in corner overlay position"
    - "Visualizer cleans up properly when stopped"
  artifacts:
    - path: "voice/AudioVisualizer.js"
      provides: "Canvas-based waveform visualization"
      exports: ["AudioVisualizer"]
      min_lines: 60
    - path: "index.html"
      provides: "Voice toggle button and indicator container"
      contains: "voice-toggle"
    - path: "styles.css"
      provides: "Indicator styling and positioning"
      contains: "listening-indicator"
  key_links:
    - from: "voice/AudioVisualizer.js"
      to: "AudioContext"
      via: "createAnalyser + createMediaStreamSource"
      pattern: "createAnalyser|createMediaStreamSource"
---

<objective>
Create the audio visualization module and UI elements for voice mode. The waveform visualizer provides real-time visual feedback showing when the app is actively listening to the user's voice.

Purpose: Users need clear visual feedback that the app is listening. Animated waveform bars that react to actual voice input (not just a static indicator) provide confidence that the microphone is working.

Output: AudioVisualizer.js module for waveform rendering, plus HTML/CSS additions for the voice toggle button and listening indicator.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-speech-recognition-foundation/02-CONTEXT.md
@.planning/phases/02-speech-recognition-foundation/02-RESEARCH.md
@index.html
@styles.css
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AudioVisualizer module</name>
  <files>voice/AudioVisualizer.js</files>
  <action>
Create voice/AudioVisualizer.js module for canvas-based waveform visualization.

The module should export an AudioVisualizer class:

```javascript
class AudioVisualizer {
  constructor(canvas)           // canvas is the HTML canvas element
  start(mediaStream)            // Start visualization with getUserMedia stream
  stop()                        // Stop visualization and cleanup resources
  setErrorState(isError)        // Change color to indicate error/retry state
}
```

Implementation details:

1. In constructor:
   - Store canvas reference
   - Get 2D context
   - Initialize audioContext, analyser, source, animationFrameId as null
   - Set default colors: normalColor = '#22c55e' (green), errorColor = '#f59e0b' (amber)

2. In start(mediaStream):
   - Create AudioContext (handle potential browser prefixes)
   - Create AnalyserNode with fftSize = 256 for clear bars
   - Set smoothingTimeConstant = 0.8 for responsive but smooth animation
   - Create MediaStreamSource from stream
   - Connect source -> analyser (NOT to destination - avoid audio feedback)
   - Create Uint8Array buffer for frequency data
   - Start animation loop with requestAnimationFrame

3. Animation loop (draw function):
   - Store animationFrameId = requestAnimationFrame(draw)
   - Get frequency data: analyser.getByteFrequencyData(dataArray)
   - Clear canvas with transparent background
   - Draw 8-12 vertical bars based on frequency data
   - Use fewer bins from the data (pick every Nth value) for cleaner look
   - Bar height proportional to frequency value
   - Bar color based on isError state

4. In stop():
   - cancelAnimationFrame(animationFrameId)
   - Stop all tracks on the stream: stream.getTracks().forEach(t => t.stop())
   - Close audioContext
   - Clear canvas
   - Reset all references to null

5. In setErrorState(isError):
   - Store error state for next draw cycle
   - Color will update automatically on next frame

Canvas drawing specifics (from RESEARCH.md):
- Canvas size should be small: ~80x40 pixels (will be scaled by CSS)
- Draw bars from bottom up
- Leave small gaps between bars
- Bars should have slight rounding for polish
  </action>
  <verify>
1. Create test HTML with canvas element
2. Call navigator.mediaDevices.getUserMedia({ audio: true })
3. Pass stream to visualizer.start()
4. Speak into mic and observe animated bars
5. Call stop() and verify cleanup (no ongoing animation)
  </verify>
  <done>
- AudioVisualizer module exists at voice/AudioVisualizer.js
- Waveform bars animate in response to voice input
- stop() properly cleans up all resources
- setErrorState changes bar color to amber
  </done>
</task>

<task type="auto">
  <name>Task 2: Add voice toggle and indicator to HTML/CSS</name>
  <files>index.html, styles.css</files>
  <action>
Add UI elements for voice mode to the teleprompter view.

In index.html, inside .controls-row, add a voice toggle button after the fullscreen button:

```html
<button id="voice-toggle" class="control-btn" title="Enable voice mode">Voice</button>
```

Add the listening indicator overlay (positioned in top-right corner):

```html
<!-- Inside #teleprompter-view, after .controls-overlay -->
<div id="listening-indicator" class="hidden">
  <canvas id="waveform-canvas" width="80" height="40"></canvas>
</div>
```

In styles.css, add styles for the listening indicator:

```css
/* Listening indicator - corner overlay */
#listening-indicator {
  position: fixed;
  top: 20px;
  right: 20px;
  padding: 8px 12px;
  background: rgba(0, 0, 0, 0.7);
  border-radius: 8px;
  z-index: 1000;
  display: flex;
  align-items: center;
  gap: 8px;
}

#listening-indicator.hidden {
  display: none;
}

#waveform-canvas {
  display: block;
  width: 80px;
  height: 40px;
}
```

Add visual state for voice toggle when active:

```css
/* Voice toggle active state */
#voice-toggle.active {
  background: #22c55e;
  color: white;
}

#voice-toggle:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}
```

The indicator should:
- Be visible even in fullscreen mode (position: fixed + z-index: 1000)
- Have a subtle dark background to ensure visibility against any content
- Stay in top-right corner regardless of scroll position
- Be completely hidden when voice mode is off (not just invisible)
  </action>
  <verify>
1. Open index.html in browser
2. Enter teleprompter mode
3. Verify Voice button appears in control bar
4. Manually remove 'hidden' class from #listening-indicator in DevTools
5. Verify indicator appears in top-right corner
6. Enter fullscreen - indicator should still be visible
  </verify>
  <done>
- Voice toggle button appears in teleprompter controls
- Listening indicator container exists with canvas
- Indicator positioned in top-right corner
- Indicator visible in fullscreen mode
- Toggle has active/disabled states styled
  </done>
</task>

</tasks>

<verification>
Manual testing checklist:
1. Voice button visible in teleprompter control bar
2. Indicator container positioned correctly (top-right, always visible)
3. AudioVisualizer renders bars when given audio stream
4. Bars respond to voice volume/frequency
5. Stop properly cleans up (no console errors, animation stops)
6. Error state changes bar color to amber
</verification>

<success_criteria>
- AudioVisualizer module is self-contained and reusable
- UI elements ready for integration with SpeechRecognizer
- Visual feedback is clear and responsive to actual voice input
- All elements work correctly in fullscreen mode
</success_criteria>

<output>
After completion, create `.planning/phases/02-speech-recognition-foundation/02-02-SUMMARY.md`
</output>
