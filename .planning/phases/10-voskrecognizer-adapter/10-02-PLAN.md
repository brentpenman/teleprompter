---
phase: 10-voskrecognizer-adapter
plan: 02
type: execute
wave: 2
depends_on: [10-01]
files_modified:
  - voice/VoskRecognizer.js
autonomous: true

must_haves:
  truths:
    - "VoskRecognizer captures microphone audio via getUserMedia"
    - "VoskRecognizer processes audio through Vosk recognizer"
    - "VoskRecognizer properly cleans up audio resources and WASM memory on stop"
    - "Audio pipeline runs at 16kHz sample rate (Vosk requirement)"
    - "Recognition runs continuously without auto-restart logic"
  artifacts:
    - path: "voice/VoskRecognizer.js"
      provides: "Complete audio pipeline implementation"
      contains: "getUserMedia"
      min_lines: 200
  key_links:
    - from: "voice/VoskRecognizer.js start()"
      to: "navigator.mediaDevices.getUserMedia"
      via: "Microphone access"
      pattern: "getUserMedia"
    - from: "voice/VoskRecognizer.js"
      to: "AudioContext"
      via: "Audio processing pipeline"
      pattern: "createAudioContext|createMediaStreamSource|createScriptProcessor"
    - from: "voice/VoskRecognizer.js"
      to: "vosk-browser KaldiRecognizer"
      via: "acceptWaveform calls"
      pattern: "acceptWaveform"
    - from: "voice/VoskRecognizer.js stop()"
      to: "recognizer.remove()"
      via: "WASM cleanup"
      pattern: "\\.remove\\(\\)"
---

<objective>
Implement complete audio capture and processing pipeline in VoskRecognizer's start(), stop(), pause(), resume() methods. This connects the microphone to Vosk's WASM recognizer and handles resource cleanup to prevent memory leaks.

Purpose: Enable real-time speech recognition with <500ms latency (VOSK-09) and stable memory usage over 60+ minute sessions (VOSK-10). Fulfill requirements for continuous recognition (VOSK-03), microphone capture (VOSK-06), and resource cleanup (VOSK-07).

Output: Fully functional audio pipeline from microphone to Vosk recognizer with proper cleanup.
</objective>

<execution_context>
@/Users/brent/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brent/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/10-voskrecognizer-adapter/10-RESEARCH.md
@.planning/phases/10-voskrecognizer-adapter/10-01-SUMMARY.md
@voice/VoskRecognizer.js
@voice/SpeechRecognizer.js
</context>

<tasks>

<task type="auto">
  <name>Implement audio pipeline in start() method</name>
  <files>voice/VoskRecognizer.js</files>
  <action>
Update VoskRecognizer.js start() method with complete audio pipeline:

1. Keep existing checks (model loaded, already listening)

2. Add microphone capture (matching SpeechRecognizer error handling):
```javascript
try {
  // Request microphone with specific constraints for Vosk
  this._stream = await navigator.mediaDevices.getUserMedia({
    audio: {
      channelCount: 1,           // Mono (Vosk requirement)
      sampleRate: 16000,         // 16kHz (Vosk requirement)
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true
    }
  });
} catch (err) {
  this._shouldBeListening = false;
  const isFatal = err.name === 'NotAllowedError';
  this._options.onError?.(err.name, isFatal);
  if (isFatal) {
    this._options.onStateChange?.('error');
  }
  throw err;
}
```

3. Create AudioContext with 16kHz sample rate:
```javascript
this._audioContext = new (window.AudioContext || window.webkitAudioContext)({
  sampleRate: this._sampleRate // 16000
});
```

4. Create KaldiRecognizer from model:
```javascript
this._recognizer = new this._model.KaldiRecognizer(this._sampleRate);
```

5. Set up audio processing pipeline (from RESEARCH.md Pattern 3):
```javascript
// Create source from microphone stream
this._source = this._audioContext.createMediaStreamSource(this._stream);

// Create ScriptProcessor (4096 buffer for <500ms latency)
this._processor = this._audioContext.createScriptProcessor(4096, 1, 1);

// Process audio buffers
this._processor.onaudioprocess = (event) => {
  try {
    // Feed audio to Vosk recognizer
    this._recognizer.acceptWaveform(event.inputBuffer);
  } catch (err) {
    console.error('Vosk processing error:', err);
    this._options.onError?.('audio-processing', false);
  }
};

// Connect pipeline: microphone -> processor -> (vosk in worker)
// Do NOT connect to destination (avoid audio feedback)
this._source.connect(this._processor);
```

6. Update state and call callback:
```javascript
this._options.onStateChange?.('listening');
```

Note: Event mapping (result/partialresult -> onTranscript) is handled in Plan 03.
  </action>
  <verify>
1. Check VoskRecognizer.js has getUserMedia call with correct constraints
2. Verify AudioContext created with sampleRate: 16000
3. Verify KaldiRecognizer created after AudioContext: this._recognizer = new this._model.KaldiRecognizer(this._sampleRate)
4. Verify ScriptProcessor created with buffer size 4096
5. Verify acceptWaveform called in onaudioprocess handler
6. Verify error handling for microphone permission errors
7. Test that start() throws error when called before loadModel() (requirement from Plan 01)
  </verify>
  <done>start() method captures microphone and sets up complete audio processing pipeline</done>
</task>

<task type="auto">
  <name>Implement resource cleanup in stop() method</name>
  <files>voice/VoskRecognizer.js</files>
  <action>
Update VoskRecognizer.js stop() method with comprehensive cleanup (from RESEARCH.md Pattern 4):

Replace stub implementation with full cleanup sequence:

```javascript
async stop() {
  this._shouldBeListening = false;

  // 1. Stop audio processing first
  if (this._processor) {
    this._processor.disconnect();
    this._processor.onaudioprocess = null;
    this._processor = null;
  }

  if (this._source) {
    this._source.disconnect();
    this._source = null;
  }

  // 2. Stop media tracks (release microphone)
  if (this._stream) {
    this._stream.getTracks().forEach(track => track.stop());
    this._stream = null;
  }

  // 3. Close AudioContext
  if (this._audioContext && this._audioContext.state !== 'closed') {
    await this._audioContext.close();
    this._audioContext = null;
  }

  // 4. Free WASM resources (CRITICAL for preventing memory leaks - VOSK-07, VOSK-10)
  if (this._recognizer) {
    this._recognizer.remove(); // Frees recognizer memory
    this._recognizer = null;
  }

  // Note: Do NOT call model.terminate() here - model should be reused across start/stop cycles
  // Model lifecycle managed externally (singleton pattern from RESEARCH.md)

  this._options.onStateChange?.('idle');
}
```

Critical ordering:
1. Disconnect audio nodes first (stops processing)
2. Stop media tracks (releases microphone)
3. Close AudioContext (releases audio resources)
4. Call recognizer.remove() (frees WASM memory)
5. Do NOT terminate model (it's expensive to recreate, should be reused)
  </action>
  <verify>
1. Check stop() disconnects processor and source
2. Verify stop() stops media tracks via getTracks().forEach(track => track.stop())
3. Verify stop() closes AudioContext
4. Verify stop() calls recognizer.remove()
5. Verify stop() does NOT call model.terminate() (model reused)
  </verify>
  <done>stop() method properly cleans up all audio resources and WASM memory, preventing leaks over 60+ minute sessions</done>
</task>

<task type="auto">
  <name>Implement pause() and resume() methods</name>
  <files>voice/VoskRecognizer.js</files>
  <action>
Update VoskRecognizer.js pause() and resume() methods to handle visibility changes:

**pause() implementation:**
```javascript
pause() {
  if (!this._shouldBeListening) return;

  this._isPaused = true;

  // Disconnect processor but keep everything else ready for resume
  if (this._processor && this._source) {
    this._source.disconnect(this._processor);
  }

  this._options.onStateChange?.('idle');
}
```

**resume() implementation:**
```javascript
resume() {
  if (!this._isPaused) return;

  this._isPaused = false;

  // Reconnect processor to resume audio processing
  if (this._processor && this._source) {
    this._source.connect(this._processor);
  }

  this._options.onStateChange?.('listening');
}
```

Key difference from SpeechRecognizer:
- SpeechRecognizer calls stop()/start() on pause/resume (Web Speech API limitation)
- VoskRecognizer just disconnects/reconnects audio graph (more efficient, Vosk stays alive)
- No need to recreate recognizer, AudioContext, or stream
  </action>
  <verify>
1. Check pause() disconnects source from processor but keeps resources alive
2. Verify resume() reconnects source to processor
3. Verify pause()/resume() don't create new audio resources
4. Verify state changes called correctly
  </verify>
  <done>pause() and resume() methods efficiently handle visibility changes without recreating audio pipeline</done>
</task>

</tasks>

<verification>
1. Manually test microphone access: VoskRecognizer.start() triggers browser permission prompt
2. Check AudioContext created with 16kHz sample rate (log this._audioContext.sampleRate)
3. Verify ScriptProcessor connected to microphone (audio should flow to Vosk)
4. Test stop() releases microphone (indicator light should turn off)
5. Test pause()/resume() work without recreating pipeline
6. Check Chrome DevTools memory profiler: memory doesn't leak over multiple start/stop cycles
</verification>

<success_criteria>
- start() method captures microphone with correct constraints (16kHz, mono)
- AudioContext created with sampleRate: 16000
- ScriptProcessor buffer size 4096 (for <500ms latency target)
- Audio pipeline connects: mic -> source -> processor -> Vosk recognizer
- stop() method performs complete cleanup (disconnect, stop tracks, close context, remove recognizer)
- WASM resources freed via recognizer.remove() (prevents memory leaks)
- pause()/resume() work efficiently without recreating pipeline
- VOSK-03, VOSK-06, VOSK-07, VOSK-09, VOSK-10 requirements satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/10-voskrecognizer-adapter/10-02-SUMMARY.md`
</output>
